#add server info
#- name: hatakeyama-llm-team/Tanuki-8B-Instruct
#  PORT: 8000
#  max-model-len: 3000
#  gpu-memory-utilization: 0.8
#  GPU_ID: 0
#  template1 : "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n\n### 指示:\n"
#  template2 : "\n\n### 応答:\n"
#  max_tokens: 2000

- name: weblab-GENIAC/Tanuki-8B-dpo-v1.0
  PORT: 8000
  max-model-len: 2048
  gpu-memory-utilization: 0.8
  GPU_ID: 0
  #template1 : "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。"
  template1 : "<s>以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n\n### 指示:\n"
  #template2 : ""
  template2 : "\n\n### 応答:\n"
  max_tokens: 1000

- name: cyberagent/calm3-22b-chat
  PORT: 8001
  max-model-len: 3000
  gpu-memory-utilization: 0.8
  GPU_ID: 1
  template1 : "<|im_start|>system\nあなたは親切なAIアシスタントです。<|im_end|>\n<|im_start|>user\n"
  template2 : "<|im_end|>\n<|im_start|>assistant"
  max_tokens: 2000

- name: team-hatakeyama-phase2/Tanuki-8x8B-dpo-v1.0
  PORT: 8002
  max-model-len: 2048
  gpu-memory-utilization: 0.8
  GPU_ID: 2,3
  #template1 : "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。"
  template1 : "<s>以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n\n### 指示:\n"
  #template2 : ""
  template2 : "\n\n### 応答:\n"
  max_tokens: 1000
  tensor-parallel-size: 2
#--trust-remote-code 

- name: karakuri-ai/karakuri-lm-8x7b-chat-v0.1
  PORT: 8003
  model: karakuri-ai/karakuri-lm-8x7b-chat-v0.1
  max-model-len: 4000
  max_tokens: 1000
  GPU_ID: 4,5
  tensor-parallel-size: 2
  template1 : "<s>[INST]"
  template2 : "[/INST]"

- name: tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1
  PORT: 8004
  model: tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1
  max-model-len: 3000
  max_tokens: 500
  GPU_ID: 6,7
  tensor-parallel-size: 2
  template1 : "<|begin_of_text|><|start_header_id|>system<|end_header_id|>あなたは誠実で優秀な日本人のアシスタントです。<|eot_id|><|start_header_id|>user<|end_header_id|>"
  template2 : "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
  
#gpt3.5: api keyで使う
- name: gpt-3.5-turbo
  PORT: 8005
  max-model-len: 2000
  GPU_ID: 0
#gpt4o-mini api keyで使う
- name: gpt-4o-mini-2024-07-18
  PORT: 8005
  max-model-len: 2000
  GPU_ID: 0
#gpt4o api keyで使う
- name: gpt-4o-2024-05-13
  PORT: 8005
  max-model-len: 2000
  GPU_ID: 0
#plamo api keyで使う
- name: plamo-beta
  PORT: 8005
  max-model-len: 2000
  GPU_ID: 0







#- name: Rakuten/RakutenAI-7B-chat
#  PORT: 8003
#  model: Rakuten/RakutenAI-7B-chat
#  max-model-len: 4000
#  gpu-memory-utilization: 0.8
#  max_tokens: 2000
#  GPU_ID: 6
#  template1 : "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: ASSISTANT:"
#  template2 : "ASSISTANT:"

#8x8bの注意点
#conda activate eval3
#export LIBRARY_PATH="/usr/local/cuda-12.2/lib64/stubs:$LIBRARY_PATH"

#nemotronはapi keyで使う
#- name: nvidia/Nemotron-4-340B-Instruct
#  PORT: 9999
#  max-model-len: 4000
#  GPU_ID: 0

#- name: microsoft/Phi-3-medium-128k-instruct
#  PORT: 8001
#  max-model-len: 4000
#  gpu-memory-utilization: 0.4
#  GPU_ID: 0
#  template1 : "<|user|>\n"
#  template2 : "<|end|>\n<|assistant|>"
#  max_tokens: 2000

#- name: Qwen/Qwen2-57B-A14B-Instruct
#  PORT: 8003
#  model: Qwen/Qwen2-57B-A14B-Instruct
#  max-model-len: 4000
#  max_tokens: 2000
#  GPU_ID: 1,2
#  tensor-parallel-size: 2
#  template1 : "<|im_start|>あなたは有用なアシスタントです。次の質問に日本語で回答してください。<|im_end|>\n<|im_start|>user\n"
#  template2 : "<|im_end|><|im_start|>assistant\n"


#- name: Qwen/Qwen2-7B-Instruct
#  PORT: 8003
#  model: Qwen/Qwen2-7B-Instruct
#  max-model-len: 4000
#  max_tokens: 2000
#  GPU_ID: 5
#  template1 : "<|im_start|>あなたは有用なアシスタントです。次の質問に日本語で回答してください。<|im_end|>\n<|im_start|>user\n"
#  template2 : "<|im_end|><|im_start|>assistant\n"


#mixtral 8x22bの5bitモデル
#GGUFで起動する。
#python3 -m llama_cpp.server --model /home/hatakeyama/python/ChatServer/model/Mixtral-8x22B-Instruct-v0.1.Q5_K_M-00001-of-00004.gguf --port 8011 --n_gpu_layers 300
#- name: models--mistralai--Mixtral-8x22B-Instruct-v0.1
#  PORT: 8011
#  model: models--mistralai--Mixtral-8x22B-Instruct-v0.1
#  max-model-len: 4000
#  max_tokens: 2000
#  GPU_ID: 6,7
#  template1 : "<s>[INST]日本語で回答しなさい。特に指示がない場合、日本語のみで回答しなさい。"
#  template2 : "[/INST]"




#templateが間違っているのか、うまく動かない
#- name: llm-jp/llm-jp-13b-instruct-full-ac_001_16x-dolly-ichikara_004_001_single-oasst-oasst2-v2.0
#  PORT: 8004
#  max-model-len: 4000
#  gpu-memory-utilization: 0.4
#  GPU_ID: 2
#  #template1 : "### 指示:\n以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。"
#  #template1 : "### 指示:\n"
#  template1 : "<s|LLM-jp>以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n\n### 指示:\n"
#  #template1 : "<s|LLM-jp>"
#  template2 : "\n\n### 応答:\n"
#  #template2 : ""
#  #template2 : ""
#  max_tokens: 2000